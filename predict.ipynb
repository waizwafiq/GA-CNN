{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Convolutional layer 1: 3 input channels, 16 output channels, 3x3 kernel size, stride of 1, padding of 1\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling with 2x2 kernel and stride of 2\n",
    "\n",
    "        # Convolutional layer 2: 16 input channels, 32 output channels, 3x3 kernel size, stride of 1, padding of 1\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling with 2x2 kernel and stride of 2\n",
    "\n",
    "        # Fully connected layer 1: Input size 32*56*56 (224/2^2), output size 64\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Fully connected layer 2: Input size 64, output size 2\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # Apply convolutional layer 1\n",
    "        x = self.relu1(x)  # Apply ReLU activation function\n",
    "        x = self.pool1(x)  # Apply max pooling\n",
    "\n",
    "        x = self.conv2(x)  # Apply convolutional layer 2\n",
    "        x = self.relu2(x)  # Apply ReLU activation function\n",
    "        x = self.pool2(x)  # Apply max pooling\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "\n",
    "        x = self.fc1(x)  # Apply fully connected layer 1\n",
    "        x = self.relu3(x)  # Apply ReLU activation function\n",
    "        x = self.fc2(x)  # Apply fully connected layer 2\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),  # Convert images to tensors\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "        # transforms.Lambda(lambda x:x.view(-1))  #this flatten 28*28 into a 784 vector for each image\n",
    "    ])\n",
    "    \n",
    "    # Load the saved model from file\n",
    "    model = CNN(5)  # Instantiate your model\n",
    "    model.load_state_dict(torch.load('./models/model_v1.pth'))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Apply the transformation to the image\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Make the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_prob, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    # # Return the predicted class and probability score\n",
    "    # if predicted_class.item() == 0:\n",
    "    #     authenticity = \"Authentic\"\n",
    "    # else:\n",
    "    #     authenticity = \"Counterfeit\"\n",
    "\n",
    "    return predicted_class.item(), predicted_prob.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"test4.jpeg\")\n",
    "result = predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wix3001_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
